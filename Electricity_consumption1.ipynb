{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSING0097 Group Coursework (Notebook 2) - F5:  \n",
    "\n",
    "## Time series data continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook you must conduct a similar analysis to the one you worked through in Notebook 1.\n",
    "\n",
    "To do this we have selected several sources of data, from recent reserach papers and commercial challenge prizes, that you can from the basis of your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSIN0097: Predictive Analytics (18/19), Group Project, Team Members, Team F5:\n",
    "- Daria Golova (17145084)<br>\n",
    "- Bartosz Kultys (18062858)<br>\n",
    "- Chi Chung Yuen (Kelvin) (15027396)<br>\n",
    "- Nanistya Respati Probosutedjo (1713278)<br>\n",
    "- Tjark Petersen (17130626)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>COURSE ASSESSMENT (~1200 words)</b> \n",
    "\n",
    "<p>This part of the assessment is based on answering/commenting/making observations on various sections throughout this Notebook.<p> \n",
    "\n",
    "<p>Course assessment blocks are highlighted in  orange (same color as this cell) throughout the Notebook.<p> \n",
    "<p>Please follow the instructions in each block. Please look at this markup cell and format your responses in a similar manner</p>\n",
    "\n",
    "<b> NOTE: All comments will be made in blue markup cells for uniformity and ease of identification in unexpected areas, accompanied with word count. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents - Project Template\n",
    "\n",
    " Load libraries\n",
    "\n",
    "1. [Problem Comprehention](#problem)\n",
    "    * Overview\n",
    "    * Problem Description\n",
    " \n",
    " \n",
    "2. [Data Comprehention](#data)\n",
    "    * Descriptive statistics\n",
    "    * Data visualizations\n",
    "  \n",
    "  \n",
    "3. [Data Preparation](#prep)\n",
    "    * Feature engineering\n",
    "    * Data transformation (normalisation, balancing, spliting)\n",
    "  \n",
    "  \n",
    "4. [Fitting the Algorithms](#alg)\n",
    "    * Experimental setup\n",
    "    * Naive forecast\n",
    "    * Data analysis\n",
    "    * Linear models \n",
    "    * Supervised learning formulation\n",
    "    * Ensemble methods\n",
    "    * Advanced methods\n",
    "  \n",
    "  \n",
    "5. [Evaluation](#assesment)\n",
    "  \n",
    "  \n",
    "6. [Finalize Model and Summary](#final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import lag_plot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import random\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#from arch import arch_model #for GARCH\n",
    "\n",
    "from scipy.stats import probplot, shapiro\n",
    "\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "#View all columns of dataframes\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "#View all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "#pretty printing of dataframes in Jupyter notebook\n",
    "import IPython\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<h1 align=\"center\"> 1. Problem Comprehension </h1> <br>\n",
    "<a id=\"problem\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please set out the selected data set/s you will use for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load the data\n",
    "#d = pd.read_csv('household_power_consumption.txt', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# The first value of Sub_metering_1 is 0 whoich will lead to an ffill of 0 later on, quick solution:\n",
    "d.Sub_metering_1 = d.Sub_metering_1.convert_objects(convert_numeric=True)\n",
    "d.iloc[0,6] = d.Sub_metering_1.mean()\n",
    "# as seen above, missing values are marked with \"?\", % of nan values, then median imputation\n",
    "df = d\n",
    "df = df.replace(to_replace='?', value= np.nan)\n",
    "df = df.replace(to_replace= '0.000', value= np.nan)\n",
    "df = df.replace(to_replace= '0', value= np.nan)\n",
    "df = df.replace(to_replace= '0.0', value= np.nan)\n",
    "df = df.replace(to_replace= 0, value= np.nan)\n",
    "\n",
    "def check_null(data):\n",
    "    nlist = list()\n",
    "    for col in data.columns:\n",
    "        nlist.append(len([i for i in data[col].isnull() if i==True])/data.shape[0])\n",
    "    labels = [i for i in data.columns]\n",
    "    d_null=pd.DataFrame({'Columns': labels, 'Null%': nlist})\n",
    "    return d_null\n",
    "\n",
    "check_null(df)\n",
    "\n",
    "# NAN values but only 1.25% in each column,impute forward\n",
    "df.fillna(method = 'ffill', inplace=True)\n",
    "print('Imputation done.')\n",
    "\n",
    "# check whether imputation is complete\n",
    "print(check_null(df))\n",
    "\n",
    "# make numbers floats\n",
    "d = df.convert_objects(convert_numeric=True)\n",
    "\n",
    "# check whether dtype has been converted to float\n",
    "print(d.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# deal with date time format - takes couple of minutes though but gives us a time series element (datetime object) which is useful:\n",
    "d.loc[:,'log'] = pd.to_datetime(df.Date.astype(str)+' '+d.Time.astype(str))\n",
    "d = d.set_index(pd.DatetimeIndex(d['log']))\n",
    "d.drop(columns=['log'],inplace = True)\n",
    "d = d.resample('D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>1209.176</td>\n",
       "      <td>44.942</td>\n",
       "      <td>93552.53</td>\n",
       "      <td>5180.8</td>\n",
       "      <td>444.281631</td>\n",
       "      <td>797.0</td>\n",
       "      <td>5862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>3390.460</td>\n",
       "      <td>238.658</td>\n",
       "      <td>345725.32</td>\n",
       "      <td>14398.6</td>\n",
       "      <td>3466.958222</td>\n",
       "      <td>5153.0</td>\n",
       "      <td>19464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>2203.826</td>\n",
       "      <td>194.526</td>\n",
       "      <td>347373.64</td>\n",
       "      <td>9247.2</td>\n",
       "      <td>2475.000000</td>\n",
       "      <td>3790.0</td>\n",
       "      <td>20050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1666.194</td>\n",
       "      <td>204.410</td>\n",
       "      <td>348479.01</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>2313.000000</td>\n",
       "      <td>8417.0</td>\n",
       "      <td>15904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>2225.748</td>\n",
       "      <td>201.092</td>\n",
       "      <td>348923.61</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>20147.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power    Voltage  \\\n",
       "log                                                                 \n",
       "2006-12-16             1209.176                 44.942   93552.53   \n",
       "2006-12-17             3390.460                238.658  345725.32   \n",
       "2006-12-18             2203.826                194.526  347373.64   \n",
       "2006-12-19             1666.194                204.410  348479.01   \n",
       "2006-12-20             2225.748                201.092  348923.61   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "log                                                                           \n",
       "2006-12-16            5180.8      444.281631           797.0          5862.0  \n",
       "2006-12-17           14398.6     3466.958222          5153.0         19464.0  \n",
       "2006-12-18            9247.2     2475.000000          3790.0         20050.0  \n",
       "2006-12-19            7094.0     2313.000000          8417.0         15904.0  \n",
       "2006-12-20            9313.0     1440.000000          3939.0         20147.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>SECTION COMPREHENSION</b>\n",
    "    \n",
    " 1.25% of each attributes have missing values ('?'s and '0's). Unknown values have been replaced with NaNs and further imputed with values of the previous time period. Dtype is converted into floats for improved data comprehension and the data resampled to daily.\n",
    "\n",
    "<b>\n",
    "<b>\n",
    "Word count: 42\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "A dataset regarding electricity usage is provided for a household. \n",
    "\n",
    "Key metrics: \n",
    "\n",
    "- four years (2006 - 2010);\n",
    "- recorded every minute;\n",
    "- 2,075,259 records; and\n",
    "- seven variables (active power, reactive power, voltage, global intensity, sub-metering 1, sub-metering 2, and sub-metering 3). \n",
    "\n",
    "<br>\n",
    "Purpose: use historical data to predict future energy consumption rates. ARIMA model is used, and further corrected using alternative models e.g. random forests, and LSTMS. \n",
    "<br>\n",
    "<br>\n",
    "Benefits the study:\n",
    "\n",
    "- billing projections for electricity companies; and \n",
    "- investment decisions for cost-saving outcomes of more environmentally friendly electricity options. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 93\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<h1 align=\"center\"> 2. Data Comprehension </h1> <br>\n",
    "<a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape\n",
    "d.head(8)\n",
    "d.info()\n",
    "d.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>1. ASSESSMENT (~100 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "The code in this second section will be clarified through visualisations in section 3.3 - Data analysis. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 17\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<h1 align=\"center\"> 3. Data Preparation </h1> <br>\n",
    "<a id=\"prep\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please see previous data preparations in the overview section of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>1. ASSESSMENT (~100 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<h1 align=\"center\"> 4. Fitting the Algorithms </h1> <br>\n",
    "<a id=\"alg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting data into train/test\n",
    "split = int(0.5 * len(d))\n",
    "train, test = d.iloc[:split].reset_index(), d.iloc[split:].reset_index()\n",
    "\n",
    "train.to_csv('train.csv',index=False, index_label=False)\n",
    "test.to_csv('test.csv',index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>2. ASSESSMENT (~100 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "Initially, a training set of 10% was allocated. However, to improve performance of the model, training set will be set as 50%. In some cases, increased to 60% for comparison. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 30\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Persistence model from the NB1\n",
    "# data - assume a dailre resample and a weekly time frame for the forecasting\n",
    "# persostance does not train a model so only the test data is needed here -> assue test_data\n",
    "# the persistence model forecasts the value for Monday in week 1 as Monday in week 2\n",
    "\n",
    "# get a data frame with the original columns and the shifted columns, remove the first 7 values (nans due to shift), called per_df\n",
    "test_df = test \n",
    "\n",
    "cols = ['Global_active_power', 'Global_reactive_power','Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2','Sub_metering_3']\n",
    "per_df = pd.DataFrame() \n",
    "rmse_vector = list()\n",
    "for k in cols:\n",
    "    temp_df = pd.concat([test_df[k].shift(7)[7:], test_df[k][7:]], axis=1)\n",
    "    temp_df.columns = [k+'_'+'t', k+'_'+'t+7']\n",
    "    per_df = pd.concat([per_df, temp_df], axis=1)\n",
    "    l1 = temp_df.iloc[:,0].astype(float)\n",
    "    l2 = temp_df.iloc[:,1].astype(float)\n",
    "    rmse_vector.append(sqrt(mean_squared_error(l1,l2)))\n",
    "evaluation_df = pd.DataFrame(columns = cols)\n",
    "evaluation_df.loc[0] = rmse_vector\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>3. ASSESSMENT (~100 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "Base model: persistence.\n",
    "<br>\n",
    "<br>\n",
    "Multi-step prediction is set to create a weekly forecast, therefore utilising a t-7 value for t. The analysis focuses on 'Global_active_power' only. The RMSE of 753 kilowatts is relatively high to the mean global active consumption of 1500. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 41\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show boxplot to understand range of values for each measure of energy\n",
    "d.boxplot(return_type ='dict', figsize=(15,8))\n",
    "plt.ylim(0,20000)\n",
    "plt.xlabel('Power Consumption Type', fontsize=12)\n",
    "plt.ylabel('Usage', fontsize=12)\n",
    "plt.title('Energy Usage by Power Consumption Type', fontsize=20)\n",
    "pyplot.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-metering 3 is notably more varied compared to energy consumption rates of the remaining power consumption types, with global_reactive power \n",
    "# showing least variation. It should also be noted that measures for voltage are much higher and is beyond the presentable range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset into series \n",
    "d_series = pd.DataFrame(data=d)\n",
    "\n",
    "# create plot for seven attributes to see trend\n",
    "d_series.plot(subplots=True, color='grey', figsize=(10,30))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because trend is still not clear, possibly seeing total on a monthly basis will help identify trend \n",
    "d2_series = d.resample('M').sum()\n",
    "d2_series.plot(subplots=True, legend=True, color='grey', figsize=(10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After converting the dataset into monthly basis, the trends appear to be clearer in all energy consumption types except for voltage. \n",
    "# Most consumption types show a fall in usage during the mid-year and peaks when introduced to a new month. \n",
    "# However, the trend or seasonality does not appear too apparent throughout and therefore can be considered as residual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(d2_series['Global_active_power'], c='grey')\n",
    "plt.title('Global Active Power Lag Plot')\n",
    "pyplot.show()\n",
    "lag_plot(d2_series['Global_reactive_power'],c='grey')\n",
    "pyplot.show()\n",
    "lag_plot(d2_series['Voltage'],c='grey')\n",
    "pyplot.show()\n",
    "lag_plot(d2_series['Global_intensity'],c='grey')\n",
    "pyplot.show()\n",
    "lag_plot(d2_series['Sub_metering_1'],c='grey')\n",
    "pyplot.show()\n",
    "lag_plot(d2_series['Sub_metering_2'],c='grey')\n",
    "pyplot.show()\n",
    "lag_plot(d2_series['Sub_metering_3'],c='grey')\n",
    "pyplot.show()\n",
    "\n",
    "# edit to make loop and add in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot shows how a one-step time lag correlates to the present measure. The stronger the correlation (1), the more appropriate the dataset is \n",
    "# for ARIMA usage. Measures with the highest correlation include global active power, global reactive power, global intensity, and sub-metering 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend becomes more apparent when values assessed on a monthly basis, therefore will be set for the analysis. To double check monthly trend, a graph plotting yearly measures will be created. \n",
    "def plot_series(data):\n",
    "    pyplot.figure(2, figsize=(15,10))\n",
    "    groups = data.groupby(pd.Grouper(freq='A'))\n",
    "    years = pd.DataFrame()\n",
    "    i=1\n",
    "    n_groups = len(groups)\n",
    "    for name, group in groups: \n",
    "        pyplot.subplot((n_groups*100) + 10 + i)\n",
    "        i += 1 \n",
    "        pyplot.plot(group, color='grey')\n",
    "    pyplot.xticks(rotation=90)\n",
    "    return pyplot.show()\n",
    "\n",
    "plot_series(d2_series['Global_active_power'])\n",
    "plot_series(d2_series['Global_reactive_power'])\n",
    "plot_series(d2_series['Voltage'])\n",
    "plot_series(d2_series['Global_intensity'])\n",
    "plot_series(d2_series['Sub_metering_1'])\n",
    "plot_series(d2_series['Sub_metering_2'])\n",
    "plot_series(d2_series['Sub_metering_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that daily analysis was converted into monthly to increase comprehension of seasonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_series['Global_active_power'].plot(kind='kde', color='grey')\n",
    "pyplot.show()\n",
    "d2_series['Global_reactive_power'].plot(kind='kde', color='grey')\n",
    "pyplot.show()\n",
    "d2_series['Voltage'].plot(kind='kde', color='grey')\n",
    "pyplot.show()\n",
    "d2_series['Global_intensity'].plot(kind='kde', color='grey')\n",
    "pyplot.show()\n",
    "d2_series['Sub_metering_1'].plot(kind='kde', color='grey')\n",
    "pyplot.show()\n",
    "d2_series['Sub_metering_2'].plot(kind='kde', color='grey')\n",
    "pyplot.show()\n",
    "d2_series['Sub_metering_3'].plot(kind='kde', color='grey')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>4. ASSESSMENT (~200 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>GRAPH COMPREHENSION</b>\n",
    "Note that daily analysis was converted into monthly to increase comprehension of seasonality. \n",
    "It was found that global active power is the most suitable electricity measure to be used for the time series analysis for the following reasons: <br>\n",
    "<br>\n",
    "- enough range;<br>\n",
    "- high correlation in lag plot; and <br>\n",
    "- completeness. <br>\n",
    "<br>\n",
    "Seasonality will be considered, however was inconsistent therefore does not have strong impact.<br>\n",
    "\n",
    "\n",
    "Word count: 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Check Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and summarize stationary version of time series\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adfuller_test(data):\n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    testing = adfuller(data, autolag='AIC')\n",
    "    output = pd.Series(testing[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in testing[4].items():\n",
    "        output['Critical Value (%s)'%key] = value\n",
    "    print (output)\n",
    "\n",
    "#apply adf test on the series\n",
    "result1 = adfuller_test(d['Global_active_power'])\n",
    "print('')\n",
    "result2 = adfuller_test(d['Global_reactive_power'])\n",
    "print('')\n",
    "result3 = adfuller_test(d['Voltage'])\n",
    "print('')\n",
    "result4 = adfuller_test(d['Global_intensity'])\n",
    "print('')\n",
    "result5 = adfuller_test(d['Sub_metering_1'])\n",
    "print('')\n",
    "result6 = adfuller_test(d['Sub_metering_2'])\n",
    "print('')\n",
    "result7 = adfuller_test(d['Sub_metering_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "The augmented Dickey-Fuller test was run on all univariate time series to check stationarity. Due to a value of less than 1%, null hypothesis was rejected and time series deemed stationary. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 31\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Detrend by Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series \n",
    "from matplotlib import pyplot\n",
    "import pylab\n",
    "\n",
    "# Set series1 for the Global active power variable\n",
    "df = pd.read_csv('train.csv',header=0);\n",
    "df['log'] = pd.to_datetime(df['log'].astype(str))\n",
    "series1 = pd.Series(df['Global_active_power'].values , index=df['log'])\n",
    "\n",
    "\n",
    "# create a function to difference the series\n",
    "def difference(dataset, interval):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "X = series1.values\n",
    "X = X.astype('float32')\n",
    "\n",
    "# difference the data by calling the function\n",
    "days_in_week = 7\n",
    "stationary1 = difference(X, days_in_week) \n",
    "stationary1.index = series1.index[days_in_week:] \n",
    "\n",
    "# save as csv\n",
    "stationary1.to_csv('stationary1.csv') \n",
    "\n",
    "# plot\n",
    "pyplot.figure(5,figsize=(10, 8))\n",
    "stationary1.plot()\n",
    "pyplot.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Manually Configure ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots of time series\n",
    "from statsmodels.graphics.tsaplots import plot_acf \n",
    "from statsmodels.graphics.tsaplots import plot_pacf \n",
    "#stationary 1\n",
    "\n",
    "pyplot.figure(6,figsize=(15,10)) \n",
    "pyplot.plot(211)\n",
    "pylab.ylim([-0.5,1])\n",
    "plot_acf(stationary1, ax=pyplot.gca()) \n",
    "\n",
    "pyplot.figure(7,figsize=(15,10)) \n",
    "pyplot.plot(212)\n",
    "pylab.ylim([-0.5,1])\n",
    "plot_pacf(stationary1, ax=pyplot.gca())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "In ACF and PACF, identifying lags will help determine ARIMA parameters. ARIMA is set at (3, 0, 1). The parameters result in an RMSE of 696, superior than in persistence model of RMSE 818. Building a better model may improve results. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 41 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Running the ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate manually configured ARIMA model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# Set series1 for the Global active power variable\n",
    "df = pd.read_csv('train.csv',header=0);\n",
    "df['log'] = pd.to_datetime(df['log'].astype(str))\n",
    "series1 = pd.Series(df['Global_active_power'].values , index=df['log'])\n",
    "\n",
    "# prepare data\n",
    "X = series1.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "    \n",
    "    # difference data\n",
    "    days_in_week = 7\n",
    "    diff = difference(history, days_in_week)\n",
    "    \n",
    "    # predict\n",
    "    model = ARIMA(diff, order=(3,0,1)) #using manually selected parameters\n",
    "    model_fit = model.fit(trend='nc', disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    yhat = inverse_difference(history, yhat, days_in_week)\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "    print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "    \n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "Running the ARIMA (3, 0, 1) model results in an RMSE of 683, which is better than the persistence RMSE of 752. This is a great start, but we may be able to improve the result by building a better model.\n",
    "<br>\n",
    "<br>\n",
    "Word count: 41 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Review the residual errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize ARIMA forecast residuals\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare data\n",
    "X = series1.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # difference data\n",
    "    days_in_weeks = 7\n",
    "    diff = difference(history, days_in_weeks)\n",
    "    \n",
    "    # predict\n",
    "    model = ARIMA(diff, order=(3,0,1))\n",
    "    model_fit = model.fit(trend='nc', disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    yhat = inverse_difference(history, yhat, days_in_weeks)\n",
    "    predictions.append(yhat)\n",
    "\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "\n",
    "# errors\n",
    "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
    "residuals = DataFrame(residuals)\n",
    "print(residuals.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "pyplot.figure(8,figsize=(10, 8))\n",
    "pyplot.subplot(211)\n",
    "residuals.hist(ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "residuals.plot(kind='kde', ax=pyplot.gca())\n",
    "pyplot.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "In the second graph above, it shows the density plot of the residual error values. It suggests that the errors are Gaussian, however, it may not be centered on zero.\n",
    "<br>\n",
    "<br>\n",
    "Word count: 30 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Grid search ARIMA model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search ARIMA parameters for time series\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    train_size = int(len(X) * 0.50)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        days_in_weeks = 7\n",
    "        diff = difference(history, days_in_weeks)\n",
    "        model = ARIMA(diff, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        yhat = inverse_difference(history, yhat, days_in_weeks)\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[i])\n",
    "    # calculate out of sample error\n",
    "    rmse = sqrt(mean_squared_error(test, predictions))\n",
    "    return rmse\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    rmse = evaluate_arima_model(dataset, order)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, order\n",
    "                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
    "\n",
    "# evaluate parameters\n",
    "p_values = [0,1, 3, 5]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series1.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Review residual errors for final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize ARIMA forecast residuals\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# prepare data\n",
    "X = series1.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # difference data\n",
    "    days_in_weeks = 7\n",
    "    diff = difference(history, days_in_weeks)\n",
    "    \n",
    "    # predict\n",
    "    model = ARIMA(diff, order=(3,0,2))\n",
    "    model_fit = model.fit(trend='nc', disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    yhat = inverse_difference(history, yhat, days_in_weeks)\n",
    "    predictions.append(yhat)\n",
    "\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "\n",
    "# errors\n",
    "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
    "residuals = DataFrame(residuals)\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "pyplot.figure(8,figsize=(10, 8))\n",
    "pyplot.subplot(211)\n",
    "residuals.hist(ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "residuals.plot(kind='kde', ax=pyplot.gca())\n",
    "pyplot.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "Gridsearch suggests ARIMA (3, 0, 2). Compared to ARIMA (3, 0, 1), distribution is Gaussian and less bumpy. Mean remains non-zero but closer to 0. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 25\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Finalise model and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from scipy.stats import boxcox\n",
    "import numpy\n",
    "\n",
    "# difference data\n",
    "weeks_in_days = 7\n",
    "diff = difference(X, weeks_in_days)\n",
    "\n",
    "# fit model\n",
    "model = ARIMA(diff, order=(3,0,2))\n",
    "model_fit = model.fit(trend='nc', disp=0)\n",
    "\n",
    "# save model\n",
    "model_fit.save('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load finalized model and make a prediction\n",
    "# load finalized model and make a prediction\n",
    "\n",
    "weeks_in_days = 7\n",
    "model_fit = ARIMAResults.load('model.pkl') \n",
    "yhat = float(model_fit.forecast()[0])\n",
    "yhat = inverse_difference(series1.values, yhat, weeks_in_days)\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â 4.9 Final model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate the finalized model on the validation dataset\n",
    "\n",
    "# load and prepare datasets\n",
    "history = [x for x in X]\n",
    "days_in_weeks = 7\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('train.csv',header=0);\n",
    "df['log'] = pd.to_datetime(df['log'].astype(str))\n",
    "train = pd.Series(df['Global_active_power'].values , index=df['log'])\n",
    "\n",
    "\n",
    "# load data\n",
    "# Set series1 for the Global active power variable\n",
    "df = pd.read_csv('test.csv',header=0);\n",
    "df['log'] = pd.to_datetime(df['log'].astype(str))\n",
    "validation = pd.Series(df['Global_active_power'].values , index=df['log'])\n",
    "prediction = validation #creat dummy series to hold prediction data\n",
    "\n",
    "x = train.values.astype('float32')\n",
    "y = validation.values.astype('float32')\n",
    "\n",
    "# load model\n",
    "model_fit = ARIMAResults.load('model.pkl')\n",
    "\n",
    "# make first prediction\n",
    "predictions = list()\n",
    "yhat = float(model_fit.forecast()[0])\n",
    "yhat = inverse_difference(history, yhat, days_in_weeks)\n",
    "predictions.append(yhat)\n",
    "history.append(y[0])\n",
    "print('>Predicted=%.3f, Expected=%3.f' % (yhat, y[0]))\n",
    "\n",
    "# rolling forecasts\n",
    "for i in range(1, len(y)):\n",
    "    # difference data\n",
    "    days_in_weeks = 7\n",
    "    diff = difference(history, days_in_weeks)\n",
    "    \n",
    "    # predict\n",
    "    model = ARIMA(diff, order=(3,0,2))\n",
    "    model_fit = model.fit(trend='nc', disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    yhat = inverse_difference(history, yhat, days_in_weeks)\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # observation\n",
    "    obs = y[i]\n",
    "    history.append(obs)\n",
    "    \n",
    "    prediction[i] = yhat    \n",
    "    print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(y, predictions))\n",
    "print('RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(9,figsize=(10, 8))\n",
    "train.plot(color='blue',label='train')\n",
    "validation.plot(color='green',label='validation')\n",
    "prediction.plot(color='red',label='prediction')\n",
    "txt=\"The train, test and predictive time series comparison\"\n",
    "pyplot.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "pyplot.legend(loc='upper left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "One observation is that the RMSE for testing set is higher than the training set. We can vizualise this results by plotting the train, test and predictive time series together on the same graph.\n",
    "<br>\n",
    "<br>\n",
    "Word count: 34\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 GARCH model\n",
    "- motivations: GARCH - allows the method to support changes in the time dependent volatility, such as increasing and decreasing volatility in the same series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "# Working with data\n",
    "values = d.values\n",
    "\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,6] = encoder.fit_transform(values[:,6])\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float64')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "d1 = pd.DataFrame(scaler.fit_transform(values))\n",
    "d1 = d1.set_index(d.index)\n",
    "d1.columns = [i for i in d.columns]\n",
    "\n",
    "#d1.drop([], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_modelgarch(residuals, st_residuals, lags=50):\n",
    "    results = {\n",
    "        'LM_pvalue': None,\n",
    "        'F_pvalue': None,\n",
    "        'SW_pvalue': None,\n",
    "        'AIC': None,\n",
    "        'params': {'p': None, 'q': None}\n",
    "    }\n",
    "    arch_test = het_arch(residuals, maxlag=lags)\n",
    "    shap_test = shapiro(st_residuals)\n",
    "    # We want falsey values for each of these hypothesis tests\n",
    "    results['LM_pvalue'] = [arch_test[1], arch_test[1] < .05]\n",
    "    results['F_pvalue'] = [arch_test[3], arch_test[3] < .05]\n",
    "    results['SW_pvalue'] = [shap_test[1], shap_test[1] < .05]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearchgarch(data, p_rng, q_rng):\n",
    "    top_score, top_results = float('inf'), None\n",
    "    top_models = []\n",
    "    for p in p_rng:\n",
    "        for q in q_rng:\n",
    "            try:\n",
    "                model = arch_model(data, vol='GARCH', p=p, q=q, dist='normal')\n",
    "                model_fit = model.fit(disp='off')\n",
    "                resid = model_fit.resid\n",
    "                st_resid = np.divide(resid, model_fit.conditional_volatility)\n",
    "                results = evaluate_modelgarch(resid, st_resid)\n",
    "                results['AIC'] = model_fit.aic\n",
    "                results['params']['p'] = p\n",
    "                results['params']['q'] = q\n",
    "                if results['AIC'] < top_score: \n",
    "                    top_score = results['AIC']\n",
    "                    top_results = results\n",
    "                elif results['LM_pvalue'][1] is False:\n",
    "                    top_models.append(results)\n",
    "            except:\n",
    "                continue\n",
    "    top_models.append(top_results)\n",
    "    return top_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(residuals, stan_residuals, lags=50):\n",
    "    residuals.plot(title='GARCH Residuals', figsize=(15, 10))\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "    ax[0].set_title('GARCH Standardized Residuals KDE')\n",
    "    ax[1].set_title('GARCH Standardized Resduals Probability Plot')    \n",
    "    residuals.plot(kind='kde', ax=ax[0])\n",
    "    probplot(stan_residuals, dist='norm', plot=ax[1])\n",
    "    plt.show()\n",
    "    acf = plot_acf(stan_residuals, lags=lags)\n",
    "    pacf = plot_pacf(stan_residuals, lags=lags)\n",
    "    acf.suptitle('GARCH Model Standardized Residual Autocorrelation', fontsize=20)\n",
    "    acf.set_figheight(5)\n",
    "    acf.set_figwidth(15)\n",
    "    pacf.set_figheight(5)\n",
    "    pacf.set_figwidth(15)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garchmodel(data, splits, series_column):\n",
    "    plt.plot(d1[series_column])\n",
    "    plt.title(series_column)\n",
    "    plt.show()\n",
    "    # Spliting the data\n",
    "    split = int(splits * len(data)) #Note: change the split for the faster model training\n",
    "    train, test = data[series_column][:split], data[series_column][split:]\n",
    "    \n",
    "    #do gridsearch\n",
    "    p_rng = range(0,10)\n",
    "    q_rng = range(0,10)\n",
    "    top_models = gridsearchgarch(train, p_rng, q_rng)\n",
    "    top_models\n",
    "\n",
    "    # design garch\n",
    "    garch = arch_model(train, vol='GARCH', p=top_models[0]['params']['p'], q=top_models[0]['params']['q'], dist='normal')\n",
    "    fgarch = garch.fit(disp='off') \n",
    "\n",
    "    resid = fgarch.resid\n",
    "    st_resid = np.divide(resid, fgarch.conditional_volatility)\n",
    "\n",
    "    #model results\n",
    "    print(fgarch.summary())\n",
    "    arch_test = het_arch(resid, maxlag=50)\n",
    "    shapiro_test = shapiro(st_resid)\n",
    "    print(f'Lagrange mulitplier p-value: {arch_test[1]}')\n",
    "    print(f'F test p-value: {arch_test[3]}')\n",
    "    print(f'Shapiro-Wilks p-value: {shapiro_test[1]}')\n",
    "    ts_plot(resid, st_resid)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the 3 hours before the submition the problem with arch_model from the package arch occured\n",
    "#due to the time constrain we could not deal with the problem\n",
    "#besides the results were already achived\n",
    "\n",
    "#to check the results obtained go to GARCH-result Jupyter Nootbook\n",
    "\n",
    "for i in d.columns[:7]:\n",
    "    garchmodel(d1, 0.5, i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note:\n",
    "# - omega -\n",
    "# - alfa - 22.1% of the pervious periods volatility will be passed to the next day.\n",
    "# - beta <1 no leading to a postive feedback loop for small shocks that can create runaway volatility.\n",
    "# if alfa + beta =1, model has persistent volatility and we might want to look at other models like IGARCH.\n",
    "\n",
    "# - p value is <0.05, so coeffisient has an effect\n",
    "\n",
    "# check if the model has model has captured the conditional heteroskedasticity of our time series:\n",
    "# - Lagrange multiplier test - residuals not exibit heterostedasity\n",
    "# - F-test - Data  normaly distributed (for n<2000)\n",
    "# - Sharpiro-Wilks - data normaly distributed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "The GARCH models have passed our Engel ARCH test and the standardized residuals appear approximately normal. However, it is has to capture the voliatility and all these model seak more  precice consideration\n",
    "<br>\n",
    "<br>\n",
    "Word count: 32\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>5. ASSESSMENT (~200 words) ---> For this section, please see the blue boxes above! </b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Supervised Learning formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "***supevised setup, conceptualisation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the dail average temperature (i think it is farenheit?) to the data\n",
    "climate = pd.read_csv(\"climate_data.csv\")\n",
    "climate = climate.loc[climate.STATION == 'FR000007150'].iloc[15:1472,:]\n",
    "d['climate'] = list(climate.iloc[:,3])\n",
    "climate.shape, d.shape\n",
    "# add weekend indicator\n",
    "days = list(d.index.weekday)\n",
    "weekend = [1 if (j==5 or j ==6) else 0 for j in days]\n",
    "d['weekend'] = weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(climate.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = list()\n",
    "for col in climate.columns:\n",
    "    nlist.append(len([i for i in climate[col].isnull() if i==True])/climate.shape[0])\n",
    "labels = [i for i in climate.columns]\n",
    "print(nlist)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important for technical understanding!\n",
    "\n",
    "# This is a \"multivariate multi-step time series forecasting problem\" in a supervised framework\n",
    "\n",
    "# Using the lag method to create supervised learning dataset -> here 7 time lags are used\n",
    "# Therefore we are in t0 and we predict the values t+1...t+7 (like Mo-Sun) based on t-7...t0 and the corresponding # moving window stats\n",
    "# Incorporated time stamp features (seasonality, weekend etc..)\n",
    "# Incorporated Paris weather data (temperatures) because the the measurements were taken in a place 7 miles from # Paris (temperature might add variation that can help explain the consumption, e.g. cold and rainy day vs. sunny and # warm)\n",
    "\n",
    "\n",
    "### Re-framing the problem to make it a supervised one ###\n",
    "#The issue is that we have multiple inputs as usual) but also multiple outputs (Global active power in future 7 # periods)!Â  Normal models cannot learn that, they only yield one output value. We need to re-frame the problem:\n",
    "\n",
    "# TWO APPROACHES:\n",
    "# 1) Direct multi-step approach: Build 7 classifiers, each classifies one day (all 7 based on the same data)\n",
    "# 2) Recursive multi-step approach: One-step model predicts based on window and previous forecast step,Â \n",
    "# e.g. today == Sunday, preciction(Tuesday) is a function of window history, window statistics AND # prediction(Monday)\n",
    "\n",
    "#Â  The second seems more promising. We implement the direct approach first and see whether we have time left.\n",
    "\n",
    "\n",
    "cols = ['Global_active_power', 'Global_reactive_power','Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2','Sub_metering_3','climate','weekend']\n",
    "df_sup_all = pd.DataFrame()\n",
    "for k in cols:\n",
    "        temps = d[k]\n",
    "        df_sup = pd.concat([temps.shift(7)-temps.shift(14),temps.shift(14),temps.shift(13),temps.shift(12),temps.shift(11),temps.shift(10),temps.shift(9),temps.shift(8),temps.shift(7),temps.shift(6),temps.shift(5),temps.shift(4),temps.shift(3), temps.shift(2), temps.shift(1), temps], axis=1)\n",
    "        df_sup.columns = [k+'_'+'m_change',k+'_'+'t-7', k+'_'+'t-6' ,k+'_'+'t-5' ,k+'_'+'t-4' ,k+'_'+'t-3' ,k+'_'+'t-2' ,k+'_'+'t-1' ,k+'_'+ 't-0', k+'_'+'t+1', k+'_'+'t+2', k+'_'+'t+3', k+'_'+'t+4', k+'_'+'t+5', k+'_'+'t+6',k+'_'+ 't+7']\n",
    "        m_mean = np.mean(df_sup.iloc[:,:-1], axis = 1)\n",
    "        m_min = np.min(df_sup.iloc[:,:-1], axis = 1)\n",
    "        m_max = np.max(df_sup.iloc[:,:-1], axis = 1)\n",
    "        m_std = np.std(df_sup.iloc[:,:-1], axis = 1)\n",
    "        df_sup.insert(loc=0, column = k+'_'+'m_mean', value = m_mean)\n",
    "        df_sup.insert(loc=0, column = k+'_'+'m_min', value = m_min)\n",
    "        df_sup.insert(loc=0, column = k+'_'+'m_max', value = m_max)\n",
    "        df_sup.insert(loc=0, column = k+'_'+'m_std', value = m_std)\n",
    "        df_sup_all = pd.concat([df_sup_all,df_sup], axis = 1)\n",
    "        \n",
    "# delete the first 14 rows due to the time lags! \n",
    "df_sup_all = df_sup_all.iloc[14:,:]\n",
    "\n",
    "# note: the test, train split from earlier must be incorporated again, since this is the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1443 days to forecast (t+1...t+7 or equivalent to Monday to Sunday), 140 features generated plus some climate features\n",
    "df_sup_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the matriix contains 4 sliding window statistics and the 7 days previous days, and the 7 follwoing days that we need to predict (7 outcomes)\n",
    "df_sup_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised modelling, base classifiers\n",
    "***Direct approach to multistep time series***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a direct modelling approach\n",
    "data = df_sup_all.iloc[:,13:20]\n",
    "temp_df = pd.concat([df_sup_all.iloc[:,0:13], df_sup_all.iloc[:,20:33],df_sup_all.iloc[:,40:53],df_sup_all.iloc[:,60:73],df_sup_all.iloc[:,80:93],df_sup_all.iloc[:,100:113],df_sup_all.iloc[:,120:133],df_sup_all.iloc[:,140:153],df_sup_all.iloc[:,160:173]],axis = 1)\n",
    "df_direct = pd.concat([temp_df,data],axis = 1)\n",
    "df_direct.shape\n",
    "df_direct_fp = df_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_direct = scaler.fit_transform(df_direct)\n",
    "df_direct = pd.DataFrame(df_direct)\n",
    "n_train = int(0.5 * len(d))\n",
    "train_X = df_direct.iloc[:n_train,:117]\n",
    "train_y = df_direct.iloc[:n_train,117:]\n",
    "test_X = df_direct.iloc[n_train:,:117]\n",
    "test_y = df_direct.iloc[n_train:,117:]\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy for the polynomial regression only\n",
    "df_direct_fp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>SECTION COMPREHENSION</b>\n",
    "    <br>\n",
    "Data is normalised by using a scaler. Features are in range 0 to 1 from this point and used in train and test subsets. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_t_1 = LinearRegression().fit(train_X, train_y.iloc[:,0])\n",
    "reg_t_2 = LinearRegression().fit(train_X, train_y.iloc[:,1])\n",
    "reg_t_3 = LinearRegression().fit(train_X, train_y.iloc[:,2])\n",
    "reg_t_4 = LinearRegression().fit(train_X, train_y.iloc[:,3])\n",
    "reg_t_5 = LinearRegression().fit(train_X, train_y.iloc[:,4])\n",
    "reg_t_6 = LinearRegression().fit(train_X, train_y.iloc[:,5])\n",
    "reg_t_7 = LinearRegression().fit(train_X, train_y.iloc[:,6])\n",
    "\n",
    "reg_t_1_pred = pd.Series(reg_t_1.predict(test_X))\n",
    "reg_t_2_pred = pd.Series(reg_t_2.predict(test_X))\n",
    "reg_t_3_pred = pd.Series(reg_t_3.predict(test_X))\n",
    "reg_t_4_pred = pd.Series(reg_t_4.predict(test_X))\n",
    "reg_t_5_pred = pd.Series(reg_t_5.predict(test_X))\n",
    "reg_t_6_pred = pd.Series(reg_t_6.predict(test_X))\n",
    "reg_t_7_pred = pd.Series(reg_t_7.predict(test_X))\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#rmse = sqrt(mean_squared_error(test_y.iloc[:,0],reg_t_1_pred))\n",
    "#print(rmse)\n",
    "\n",
    "\n",
    "# invert scaling:\n",
    "# matrix of predicted values with shape of test_y\n",
    "yhat = pd.concat([reg_t_1_pred,reg_t_2_pred,reg_t_3_pred,reg_t_4_pred,reg_t_5_pred,reg_t_6_pred,reg_t_7_pred],axis = 1)\n",
    "\n",
    "inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = pd.DataFrame(inv_yhat).iloc[:,117:]\n",
    "\n",
    "inv_y = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,117:]\n",
    "\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)\n",
    "\n",
    "inter = [x for x in range(inv_y.shape[0])]\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step in multi-step 7 days')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>MODEL COMPREHENSION</b>\n",
    "    <br>\n",
    "Linear regression is applied with direct approach, however resulting in high levels of RMSE. It is inferred that around time step 400, variation of predictions drastically increase. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf_d = DecisionTreeRegressor()\n",
    "\n",
    "tree_t_1 = clf_d.fit(train_X, train_y.iloc[:,0])\n",
    "tree_t_2 = clf_d.fit(train_X, train_y.iloc[:,1])\n",
    "tree_t_3 = clf_d.fit(train_X, train_y.iloc[:,2])\n",
    "tree_t_4 = clf_d.fit(train_X, train_y.iloc[:,3])\n",
    "tree_t_5 = clf_d.fit(train_X, train_y.iloc[:,4])\n",
    "tree_t_6 = clf_d.fit(train_X, train_y.iloc[:,5])\n",
    "tree_t_7 = clf_d.fit(train_X, train_y.iloc[:,6])\n",
    "\n",
    "tree_t_1_pred = pd.Series(tree_t_1.predict(test_X))\n",
    "tree_t_3_pred = pd.Series(tree_t_3.predict(test_X))\n",
    "tree_t_4_pred = pd.Series(tree_t_4.predict(test_X))\n",
    "tree_t_5_pred = pd.Series(tree_t_5.predict(test_X))\n",
    "tree_t_6_pred = pd.Series(tree_t_6.predict(test_X))\n",
    "tree_t_7_pred = pd.Series(tree_t_7.predict(test_X))\n",
    "\n",
    "\n",
    "#rmse_tree = sqrt(mean_squared_error(test_y.iloc[:,0],tree_t_1_pred))\n",
    "#print(rmse_tree)\n",
    "\n",
    "tree_t_1_pred = pd.Series(tree_t_1.predict(test_X))\n",
    "tree_t_2_pred = pd.Series(tree_t_2.predict(test_X))\n",
    "tree_t_3_pred = pd.Series(tree_t_3.predict(test_X))\n",
    "tree_t_4_pred = pd.Series(tree_t_4.predict(test_X))\n",
    "tree_t_5_pred = pd.Series(tree_t_5.predict(test_X))\n",
    "tree_t_6_pred = pd.Series(tree_t_6.predict(test_X))\n",
    "tree_t_7_pred = pd.Series(tree_t_7.predict(test_X))\n",
    "\n",
    "yhat_d = pd.concat([tree_t_1_pred,tree_t_2_pred,tree_t_3_pred,tree_t_4_pred,tree_t_5_pred,tree_t_6_pred,tree_t_7_pred],axis = 1)\n",
    "\n",
    "inv_yhat_d = np.concatenate((test_X ,yhat_d), axis=1)\n",
    "inv_yhat_d = scaler.inverse_transform(inv_yhat_d)\n",
    "inv_yhat_d = pd.DataFrame(inv_yhat_d).iloc[:,117:]\n",
    "\n",
    "inv_y_d = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y_d = scaler.inverse_transform(inv_y_d)\n",
    "inv_y_d = pd.DataFrame(inv_y_d).iloc[:,117:]\n",
    "\n",
    "# RMSE and combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y_d.iloc[:,k], inv_yhat_d.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y_d.iloc[:,k], inv_yhat_d.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = [x for x in range(inv_y_d.shape[0])]\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat_d.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step in multi-step 7 days')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>MODEL COMPREHENSION</b>\n",
    "    <br>\n",
    "A non-linear decision tree is deployed to test a second supervised algorithm. An RMSE of 957 shows improved performance compared to linear regression, with less variation. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial transformation before splitting into train and test\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_features = PolynomialFeatures(degree=2)\n",
    "train_temp = df_direct_fp.iloc[:,:117]\n",
    "test_temp = df_direct_fp.iloc[:,117:]\n",
    "train_temp_poly = pd.DataFrame(polynomial_features.fit_transform(train_temp))\n",
    "test_temp.reset_index(drop=True, inplace=True)\n",
    "train_temp_poly.reset_index(drop=True, inplace=True)\n",
    "df_direct_poly = pd.concat([train_temp_poly,test_temp],axis = 1)\n",
    "df_direct_poly.shape\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_direct_poly = scaler.fit_transform(df_direct_poly)\n",
    "df_direct_poly = pd.DataFrame(df_direct_poly)\n",
    "n_train = int(0.5 * len(d))\n",
    "train_X_p = df_direct_poly.iloc[:n_train,:7021]\n",
    "train_y_p = df_direct_poly.iloc[:n_train,7021:]\n",
    "test_X_p = df_direct_poly.iloc[n_train:,:7021]\n",
    "test_y_p = df_direct_poly.iloc[n_train:,7021:]\n",
    "train_X_p.shape, train_y_p.shape, test_X_p.shape, test_y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with polynominal features\n",
    "\n",
    "rpoly_t_1 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,0])\n",
    "rpoly_t_2 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,1])\n",
    "rpoly_t_3 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,2])\n",
    "rpoly_t_4 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,3])\n",
    "rpoly_t_5 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,4])\n",
    "rpoly_t_6 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,5])\n",
    "rpoly_t_7 = LinearRegression().fit(train_X_p, train_y_p.iloc[:,6])\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#rmse = sqrt(mean_squared_error(test_y_p.iloc[:,0],rpoly_t_1_pred))\n",
    "#print(rmse)\n",
    "\n",
    "rpoly_t_1_pred = pd.Series(rpoly_t_1.predict(test_X_p))\n",
    "rpoly_t_2_pred = pd.Series(rpoly_t_2.predict(test_X_p))\n",
    "rpoly_t_3_pred = pd.Series(rpoly_t_3.predict(test_X_p))\n",
    "rpoly_t_4_pred = pd.Series(rpoly_t_4.predict(test_X_p))\n",
    "rpoly_t_5_pred = pd.Series(rpoly_t_5.predict(test_X_p))\n",
    "rpoly_t_6_pred = pd.Series(rpoly_t_6.predict(test_X_p))\n",
    "rpoly_t_7_pred = pd.Series(rpoly_t_7.predict(test_X_p))\n",
    "\n",
    "yhat = pd.concat([rpoly_t_1_pred,rpoly_t_2_pred,rpoly_t_3_pred,rpoly_t_4_pred,rpoly_t_5_pred,rpoly_t_6_pred,rpoly_t_7_pred],axis = 1)\n",
    "\n",
    "inv_yhat_p = np.concatenate((test_X_p ,yhat), axis=1)\n",
    "inv_yhat_p = scaler.inverse_transform(inv_yhat_p)\n",
    "inv_yhat_p = pd.DataFrame(inv_yhat_p).iloc[:,7021:]\n",
    "\n",
    "inv_y = np.concatenate((test_X_p, test_y_p), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,7021:]\n",
    "\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)\n",
    "# over-fitting -> rugularisation needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intertree = [x for x in range(inv_y_d.shape[0])]\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(intertree, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(intertree, inv_yhat_p.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - multi-step 7 days')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with polynominal features\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg_1 = Ridge(alpha = 1.0)\n",
    "rpoly_t_1 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,0])\n",
    "rpoly_t_2 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,1])\n",
    "rpoly_t_3 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,2])\n",
    "rpoly_t_4 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,3])\n",
    "rpoly_t_5 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,4])\n",
    "rpoly_t_6 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,5])\n",
    "rpoly_t_7 = ridgereg_1.fit(train_X_p, train_y_p.iloc[:,6])\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#rmse = sqrt(mean_squared_error(test_y_p.iloc[:,0],rpoly_t_1_pred))\n",
    "#print(rmse)\n",
    "\n",
    "rpoly_t_1_pred = pd.Series(rpoly_t_1.predict(test_X_p))\n",
    "rpoly_t_2_pred = pd.Series(rpoly_t_2.predict(test_X_p))\n",
    "rpoly_t_3_pred = pd.Series(rpoly_t_3.predict(test_X_p))\n",
    "rpoly_t_4_pred = pd.Series(rpoly_t_4.predict(test_X_p))\n",
    "rpoly_t_5_pred = pd.Series(rpoly_t_5.predict(test_X_p))\n",
    "rpoly_t_6_pred = pd.Series(rpoly_t_6.predict(test_X_p))\n",
    "rpoly_t_7_pred = pd.Series(rpoly_t_7.predict(test_X_p))\n",
    "\n",
    "yhat = pd.concat([rpoly_t_1_pred,rpoly_t_2_pred,rpoly_t_3_pred,rpoly_t_4_pred,rpoly_t_5_pred,rpoly_t_6_pred,rpoly_t_7_pred],axis = 1)\n",
    "\n",
    "inv_yhat_p = np.concatenate((test_X_p ,yhat), axis=1)\n",
    "inv_yhat_p = scaler.inverse_transform(inv_yhat_p)\n",
    "inv_yhat_p = pd.DataFrame(inv_yhat_p).iloc[:,7021:]\n",
    "\n",
    "inv_y = np.concatenate((test_X_p, test_y_p), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,7021:]\n",
    "\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge with alpha = 0.5\n",
    "ridgereg_0_5 = Ridge(alpha = 0.5)\n",
    "rpoly_t_1 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,0])\n",
    "rpoly_t_2 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,1])\n",
    "rpoly_t_3 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,2])\n",
    "rpoly_t_4 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,3])\n",
    "rpoly_t_5 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,4])\n",
    "rpoly_t_6 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,5])\n",
    "rpoly_t_7 = ridgereg_0_5.fit(train_X_p, train_y_p.iloc[:,6])\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#rmse = sqrt(mean_squared_error(test_y_p.iloc[:,0],rpoly_t_1_pred))\n",
    "#print(rmse)\n",
    "\n",
    "rpoly_t_1_pred = pd.Series(rpoly_t_1.predict(test_X_p))\n",
    "rpoly_t_2_pred = pd.Series(rpoly_t_2.predict(test_X_p))\n",
    "rpoly_t_3_pred = pd.Series(rpoly_t_3.predict(test_X_p))\n",
    "rpoly_t_4_pred = pd.Series(rpoly_t_4.predict(test_X_p))\n",
    "rpoly_t_5_pred = pd.Series(rpoly_t_5.predict(test_X_p))\n",
    "rpoly_t_6_pred = pd.Series(rpoly_t_6.predict(test_X_p))\n",
    "rpoly_t_7_pred = pd.Series(rpoly_t_7.predict(test_X_p))\n",
    "\n",
    "yhat = pd.concat([rpoly_t_1_pred,rpoly_t_2_pred,rpoly_t_3_pred,rpoly_t_4_pred,rpoly_t_5_pred,rpoly_t_6_pred,rpoly_t_7_pred],axis = 1)\n",
    "\n",
    "inv_yhat_p = np.concatenate((test_X_p ,yhat), axis=1)\n",
    "inv_yhat_p = scaler.inverse_transform(inv_yhat_p)\n",
    "inv_yhat_p = pd.DataFrame(inv_yhat_p).iloc[:,7021:]\n",
    "\n",
    "inv_y = np.concatenate((test_X_p, test_y_p), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,7021:]\n",
    "\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge with alpha = 0.1\n",
    "ridgereg_0_1 = Ridge(alpha = 0.1)\n",
    "rpoly_t_1 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,0])\n",
    "rpoly_t_2 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,1])\n",
    "rpoly_t_3 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,2])\n",
    "rpoly_t_4 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,3])\n",
    "rpoly_t_5 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,4])\n",
    "rpoly_t_6 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,5])\n",
    "rpoly_t_7 = ridgereg_0_1.fit(train_X_p, train_y_p.iloc[:,6])\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#rmse = sqrt(mean_squared_error(test_y_p.iloc[:,0],rpoly_t_1_pred))\n",
    "#print(rmse)\n",
    "\n",
    "rpoly_t_1_pred = pd.Series(rpoly_t_1.predict(test_X_p))\n",
    "rpoly_t_2_pred = pd.Series(rpoly_t_2.predict(test_X_p))\n",
    "rpoly_t_3_pred = pd.Series(rpoly_t_3.predict(test_X_p))\n",
    "rpoly_t_4_pred = pd.Series(rpoly_t_4.predict(test_X_p))\n",
    "rpoly_t_5_pred = pd.Series(rpoly_t_5.predict(test_X_p))\n",
    "rpoly_t_6_pred = pd.Series(rpoly_t_6.predict(test_X_p))\n",
    "rpoly_t_7_pred = pd.Series(rpoly_t_7.predict(test_X_p))\n",
    "\n",
    "yhat = pd.concat([rpoly_t_1_pred,rpoly_t_2_pred,rpoly_t_3_pred,rpoly_t_4_pred,rpoly_t_5_pred,rpoly_t_6_pred,rpoly_t_7_pred],axis = 1)\n",
    "\n",
    "inv_yhat_p = np.concatenate((test_X_p ,yhat), axis=1)\n",
    "inv_yhat_p = scaler.inverse_transform(inv_yhat_p)\n",
    "inv_yhat_p = pd.DataFrame(inv_yhat_p).iloc[:,7021:]\n",
    "\n",
    "inv_y = np.concatenate((test_X_p, test_y_p), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,7021:]\n",
    "\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat_p.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>MODEL COMPREHENSION</b>\n",
    "    <br>\n",
    "To further improve accuracy, polynomial transformation of feature inputs to linear and ridge regression models is conducted. Performance improves slightly for linear however ridge (alpha = 1) predicts in a more precise manner. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>6. ASSESSMENT (~200 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "This is a multi-step forecasting task. A new dataset with seven time steps prior and ahead. Additionally, rolling window statistics for each variable, weather approximation in Paris (close to where data was generated) and weekend indicators were created. Therefore, information for t-6 to t can be collected. Outcomes from t+1 to t+7 are written. A separate classifier will be created in the direct approach for each day of the week. Consequently, weekly predictions are made. RMSE scores will be averaged. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 80\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a direct modelling approach\n",
    "data = df_sup_all.iloc[:,13:20]\n",
    "temp_df = pd.concat([df_sup_all.iloc[:,0:13], df_sup_all.iloc[:,20:33],df_sup_all.iloc[:,40:53],df_sup_all.iloc[:,60:73],df_sup_all.iloc[:,80:93],df_sup_all.iloc[:,100:113],df_sup_all.iloc[:,120:133],df_sup_all.iloc[:,140:153],df_sup_all.iloc[:,160:173]],axis = 1)\n",
    "df_direct = pd.concat([temp_df,data],axis = 1)\n",
    "df_direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_direct = scaler.fit_transform(df_direct)\n",
    "df_direct = pd.DataFrame(df_direct)\n",
    "n_train = int(0.5 * len(d))\n",
    "train_X = df_direct.iloc[:n_train,:117]\n",
    "train_y = df_direct.iloc[:n_train,117:]\n",
    "test_X = df_direct.iloc[n_train:,:117]\n",
    "test_y = df_direct.iloc[n_train:,117:]\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FORESTS MULTI-STEP 7 DAYS\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers = []\n",
    "yhat = pd.DataFrame()\n",
    "for k in range(7):\n",
    "    model = RandomForestRegressor().fit(train_X, train_y.iloc[:,k])\n",
    "    yhat['rf_'+str(k)] = model.predict(test_X)\n",
    "    \n",
    "inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = pd.DataFrame(inv_yhat).iloc[:,117:]\n",
    "\n",
    "inv_y = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,117:]\n",
    "\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('----------------------------')\n",
    "print('Overall Test RMSE: %.3f' % rmse)\n",
    "\n",
    "inter=[x for x in range(inv_y.shape[0])]\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - all test data')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT BOOSTING\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "yhat = pd.DataFrame()\n",
    "for k in range(7):\n",
    "    model = GradientBoostingRegressor().fit(train_X, train_y.iloc[:,k])\n",
    "    yhat['rf_'+str(k)] = model.predict(test_X)\n",
    "    \n",
    "inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = pd.DataFrame(inv_yhat).iloc[:,117:]\n",
    "\n",
    "inv_y = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,117:]\n",
    "\n",
    "gbm_inv_y_save = inv_y.iloc[:,-1]\n",
    "gbm_inv_yhat_save = inv_yhat.iloc[:,-1]\n",
    "\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('----------------------------')\n",
    "print('Overall Test RMSE: %.3f' % rmse)\n",
    "\n",
    "inter=[x for x in range(inv_y.shape[0])]\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - all test data')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>7. ASSESSMENT (~200 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "A bagging-based, random forest (RF), and boosting-based, gradient boosting (GBM) approach is chosen to deal with the instability of non-linear methods. Both perform much better than persistence model. GBM has highest performance (average RMSE of 522). It is still wrong by circa 1/3 of average daily energy consumption. Note that for both ensembles, RMSE increased from t+1 to t+7, which makes sense because it is further in the future. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 69\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are confident, explore some of the more advanced methods that we covered in the course. \n",
    "\n",
    "For example, try and get a RNN working on the dataset you have chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section consists of serveral neural networks:<br>\n",
    "- Model 1: Multivariate time series forecasting with NN\n",
    "- Model 2: Multi-step forecasting of 7 days consumption ahead based on 1 time lag and all features available (see supervised framing section)\n",
    "- Model 3: Multi-step forecasting of 7 days consumption ahead based on 7 time lag and all features available (see supervised framing section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with data\n",
    "values = d.values\n",
    "\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,6] = encoder.fit_transform(values[:,6])\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "d1 = series_to_supervised(scaled, 1, 1)\n",
    "d1 = d1[['var1(t-1)', 'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var5(t-1)','var6(t-1)', 'var7(t-1)', 'var8(t-1)', 'var8(t)', 'var9(t)', #use to predict\n",
    "        'var1(t)', 'var2(t)', 'var3(t)', 'var4(t)', 'var5(t)', 'var6(t)', 'var7(t)', #need to predict\n",
    "        'var9(t-1)']] #can be eliminated\n",
    "\n",
    "# keep only the ones that need to be predicted\n",
    "d1.drop(['var9(t-1)'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_model(data, split_ratio, parameter_to_estemate):\n",
    "    dict1 = dict(zip([i for i in d.columns], range(-7, 0)))\n",
    "    i = dict1[parameter_to_estemate]\n",
    "    # Spliting and spaping the data\n",
    "    split = int(split_ratio * len(d)) #Note: change the split for the faster model training\n",
    "    train, test = data[:split], data[split:]\n",
    "    train_X, train_y = train.values[:, :-7], train.values[:, -7]\n",
    "    test_X, test_y = test.values[:, :-7], test.values[:, -7]\n",
    "\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    \n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], 10)) #change to have same dimentions\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = np.concatenate((yhat, test_X[:, 2:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = np.concatenate((test_y, test_X[:, 2:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print(f'{parameter_to_estemate}, RMSE: {rmse}')\n",
    "    \n",
    "    plt.figure(figsize = (30,10))\n",
    "    #train test loss\n",
    "    plt.subplot(131)\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "\n",
    "    #Plot true labels\n",
    "    plt.subplot(132)\n",
    "    inter=[x for x in range(inv_y.shape[0])]\n",
    "    plt.plot(inter, inv_y, marker='.', label=\"actual\")\n",
    "    plt.plot(inter, inv_yhat, 'r', label=\"prediction\")\n",
    "    plt.title('Predictions and actual values for t step')\n",
    "    plt.ylabel('Global_active_power', size=15)\n",
    "    plt.xlabel('Time step', size=15)\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    #Plot predicted labels with the decision boundaries\n",
    "    plt.subplot(133)\n",
    "    inter=[x for x in range(30)]\n",
    "    plt.plot(inter, inv_y[:30], marker='.', label=\"actual\")\n",
    "    plt.plot(inter, inv_yhat[:30], 'r', label=\"prediction\")\n",
    "    plt.title('Predictions and actual values for t+1 step - 1 month')\n",
    "    plt.ylabel('Global_active_power', size=15)\n",
    "    plt.xlabel('Time step', size=15)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in d.columns[:7]:\n",
    "    network_model(d1, 0.6, i )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "\n",
    "This model looks at multivariate time series forcasting with the LSTM. For better forecast model considerate climate and weekend variables.\n",
    "<br>\n",
    "<br>\n",
    "Word count: 19\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras: Multivariate time series forecasting with LSTMs\n",
    "### Models 2 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two alternatives, model2 and model3\n",
    "# Model 2 and 3 both predict multi-step although are based on different time lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 implementation: 1 time lag, all features plus weather and weekend features, \n",
    "# input format [samples, timesteps, features] = [samples, 1, 9]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = df_sup_all.iloc[:,12:20]\n",
    "temp_df = pd.concat([df_sup_all.iloc[:,32:33],df_sup_all.iloc[:,52:53],df_sup_all.iloc[:,72:73],df_sup_all.iloc[:,92:93],df_sup_all.iloc[:,112:113],df_sup_all.iloc[:,132:133],df_sup_all.iloc[:,152:153],df_sup_all.iloc[:,172:173]],axis = 1)\n",
    "data = pd.concat([temp_df,data],axis = 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "n_train = int(0.5 * len(d))\n",
    "train_X = data.iloc[:n_train,:9]\n",
    "train_X = train_X.values.reshape(train_X.shape[0],1,train_X.shape[1])\n",
    "train_y = data.iloc[:n_train,9:]\n",
    "test_X = data.iloc[n_train:,:9]\n",
    "test_X = test_X.values.reshape(test_X.shape[0],1,test_X.shape[1])\n",
    "test_y = data.iloc[n_train:,9:]\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm\n",
    "# modelling choices\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200,activation='relu',return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100,activation = 'relu',return_sequences=False))\n",
    "model.add(Dense(7))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fitting\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=20, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "\n",
    "# plot train and test performance/loss\n",
    "plt.plot(history.history['loss'],'r')\n",
    "plt.plot(history.history['val_loss'],'b')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training', 'testing'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], 9))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = pd.DataFrame(inv_yhat).iloc[:,9:]\n",
    "# invert scaling for actual\n",
    "###test_y = test_y.reshape((len(test_y), 7))\n",
    "inv_y = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,9:]\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter=[x for x in range(inv_y.shape[0])]\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - all test data')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter=[x for x in range(30)]\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(inter, inv_y.iloc[:30,-1], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:30,-1], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - 1 month')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: 7 lags, all features plus weather and weekend,\n",
    "# input format [samples, timesteps, features] = [samples, 7, 9]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = df_sup_all.iloc[:,13:20]\n",
    "temp_df_1 = pd.concat([df_sup_all.iloc[:,12:13],df_sup_all.iloc[:,32:33],df_sup_all.iloc[:,52:53],df_sup_all.iloc[:,72:73],df_sup_all.iloc[:,92:93],df_sup_all.iloc[:,112:113],df_sup_all.iloc[:,132:133],df_sup_all.iloc[:,152:153],df_sup_all.iloc[:,172:173]],axis = 1)\n",
    "temp_df_2 = pd.concat([df_sup_all.iloc[:,11:12], df_sup_all.iloc[:,31:32],df_sup_all.iloc[:,51:52],df_sup_all.iloc[:,71:72],df_sup_all.iloc[:,91:92],df_sup_all.iloc[:,111:112],df_sup_all.iloc[:,131:132],df_sup_all.iloc[:,151:152],df_sup_all.iloc[:,171:172]],axis = 1)\n",
    "temp_df_3 = pd.concat([df_sup_all.iloc[:,10:11], df_sup_all.iloc[:,30:31],df_sup_all.iloc[:,50:51],df_sup_all.iloc[:,70:71],df_sup_all.iloc[:,90:91],df_sup_all.iloc[:,110:111],df_sup_all.iloc[:,130:131],df_sup_all.iloc[:,150:151],df_sup_all.iloc[:,170:171]],axis = 1)\n",
    "temp_df_4 = pd.concat([df_sup_all.iloc[:,9:10], df_sup_all.iloc[:,29:30],df_sup_all.iloc[:,49:50],df_sup_all.iloc[:,69:70],df_sup_all.iloc[:,89:90],df_sup_all.iloc[:,109:110],df_sup_all.iloc[:,129:130],df_sup_all.iloc[:,149:150],df_sup_all.iloc[:,169:170]],axis = 1)\n",
    "temp_df_5 = pd.concat([df_sup_all.iloc[:,8:9], df_sup_all.iloc[:,28:29],df_sup_all.iloc[:,48:49],df_sup_all.iloc[:,68:69],df_sup_all.iloc[:,88:89],df_sup_all.iloc[:,108:109],df_sup_all.iloc[:,128:129],df_sup_all.iloc[:,148:149],df_sup_all.iloc[:,168:169]],axis = 1)\n",
    "temp_df_6 = pd.concat([df_sup_all.iloc[:,7:8], df_sup_all.iloc[:,27:28],df_sup_all.iloc[:,47:48],df_sup_all.iloc[:,67:68],df_sup_all.iloc[:,87:88],df_sup_all.iloc[:,107:108],df_sup_all.iloc[:,127:128],df_sup_all.iloc[:,147:148],df_sup_all.iloc[:,167:168]],axis = 1)\n",
    "temp_df_7 = pd.concat([df_sup_all.iloc[:,6:7], df_sup_all.iloc[:,26:27],df_sup_all.iloc[:,46:47],df_sup_all.iloc[:,66:67],df_sup_all.iloc[:,86:87],df_sup_all.iloc[:,106:107],df_sup_all.iloc[:,126:127],df_sup_all.iloc[:,146:147],df_sup_all.iloc[:,166:167]],axis = 1)\n",
    "data = pd.concat([temp_df_7,temp_df_6,temp_df_5,temp_df_4,temp_df_3,temp_df_2,temp_df_1,data],axis = 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "n_train = int(0.5 * len(d))\n",
    "train_X = data.iloc[:n_train,:63]\n",
    "train_X = train_X.values.reshape(train_X.shape[0],7,9)\n",
    "train_y = data.iloc[:n_train,63:]\n",
    "test_X = data.iloc[n_train:,:63]\n",
    "test_X = test_X.values.reshape(test_X.shape[0],7,9)\n",
    "test_y = data.iloc[n_train:,63:]\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling choices\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200,activation='relu',return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100,activation = 'relu',return_sequences=False))\n",
    "model.add(Dense(7))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fitting\n",
    "history = model.fit(train_X, train_y, epochs=15, batch_size=50, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "\n",
    "# plot train and test performance/loss\n",
    "plt.plot(history.history['loss'],'r')\n",
    "plt.plot(history.history['val_loss'],'b')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training', 'testing'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], 63))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = pd.DataFrame(inv_yhat).iloc[:,63:]\n",
    "# invert scaling for actual\n",
    "###test_y = test_y.reshape((len(test_y), 7))\n",
    "inv_y = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,63:]\n",
    "# calculate RMSE, combine\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('Overall Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter=[x for x in range(inv_y.shape[0])]\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - all test data')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter=[x for x in range(30)]\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(inter, inv_y.iloc[:30,-1], marker='.', label=\"actual\")\n",
    "plt.plot(inter, inv_yhat.iloc[:30,-1], 'r', label=\"prediction\")\n",
    "plt.title('Predictions and actual values for t+1 step - 1 month')\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>8. OPTIONAL ASSESSMENT (~200 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "Models 2 and 3: based on the data engineering in the supervised framing section. Model 2 is an LSTM that feeds in only 1 time lag but all available 9 features. The input structure is [#samples, timesteps, features] = [#samples, 1, 9]. It uses two LSTM layers and a 0.5 dropout to predict 7 outcomes (t+1â¦t+7). \n",
    "\n",
    "Model 3: LSTM that feeds in 7 time lag but all available variables. The input structure is [#samples, 7, 9]. The architecture is similar. Model 2 reaches an average RMSE of 553 which increases fast in predicted time steps. Model 3, although build on more lags, performs similar but the RMSE does not increase (from t+1 to t+7), therefore it is a more stable model.\n",
    "\n",
    "All models show a higher training loss compared to the testing loss (see graphs above) which logically does not make sense to us although it might have to do with the drop-outs or how Keras handles training and testing differently. Also, we are convinced that the neural nets would perform better if they would have been trained on an appropriate amount of data (we only have 728 training samples available in this case study).Â \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Word count: 195\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<h1 align=\"center\"> 5. Algorithm further assesment </h1> <br>\n",
    "<a id=\"assesment\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have trained more that two different regressors using different methods and tested it on different dataset. \n",
    "\n",
    "Comment on the comparative performance of the methods your have investigated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section contains:\n",
    "# 1) GBM - Experiment: Change the train test-test split from 50/50 to 60/40 and show that lack of data might be an issue\n",
    "# 2) GBM - Plot true vs. predicted values and visualise the performance of the best multi-step model\n",
    "# 3) Take the difference between the predictions and the true values of the t+1 step of the 7 day multi-step GBM system\n",
    "# 4) The mark up cell gives an overview about comparability of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) GBM - Experiment: Change the train test-test split from 0.5/0.5 to 0.6/0.4 and show that lack of data is an issue\n",
    "# Create a direct modelling approach\n",
    "\n",
    "data = df_sup_all.iloc[:,13:20]\n",
    "temp_df = pd.concat([df_sup_all.iloc[:,0:13], df_sup_all.iloc[:,20:33],df_sup_all.iloc[:,40:53],df_sup_all.iloc[:,60:73],df_sup_all.iloc[:,80:93],df_sup_all.iloc[:,100:113],df_sup_all.iloc[:,120:133],df_sup_all.iloc[:,140:153],df_sup_all.iloc[:,160:173]],axis = 1)\n",
    "df_direct = pd.concat([temp_df,data],axis = 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_direct = scaler.fit_transform(df_direct)\n",
    "df_direct = pd.DataFrame(df_direct)\n",
    "n_train = int(0.6 * len(d))\n",
    "train_X = df_direct.iloc[:n_train,:117]\n",
    "train_y = df_direct.iloc[:n_train,117:]\n",
    "test_X = df_direct.iloc[n_train:,:117]\n",
    "test_y = df_direct.iloc[n_train:,117:]\n",
    "#train_X.shape, train_y.shape, test_X.shape, test_y.shape\n",
    "\n",
    "# GRADIENT BOOSTING - MULTI-STEP 7 DAYS\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "yhat = pd.DataFrame()\n",
    "for k in range(7):\n",
    "    model = GradientBoostingRegressor().fit(train_X, train_y.iloc[:,k])\n",
    "    yhat['rf_'+str(k)] = model.predict(test_X)\n",
    "    \n",
    "inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = pd.DataFrame(inv_yhat).iloc[:,117:]\n",
    "\n",
    "inv_y = np.concatenate((test_X, test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = pd.DataFrame(inv_y).iloc[:,117:]\n",
    "\n",
    "gbm_inv_y_save = inv_y.iloc[:,-1]\n",
    "gbm_inv_yhat_save = inv_yhat.iloc[:,-1]\n",
    "\n",
    "temp = list()\n",
    "for k in range(7):\n",
    "    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "rmse = np.sum(temp)/7    \n",
    "print('----------------------------')\n",
    "print('Overall Test RMSE with the 60/40 split: %.3f' % rmse)\n",
    "print('Compare: Overall Test RMSE with the 50/50 split: 523ish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "#Overall Test RMSE with the 60/40 split: 506.052\n",
    "#Compare: Overall Test RMSE with the 50/50 split: 523ish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) True values vs. predictions - still far from a 45 degree line\n",
    "plt.figure(figsize = (9,9))\n",
    "plt.scatter(gbm_inv_y_save,gbm_inv_yhat_save)\n",
    "plt.title('GBM (t+1 step): True values vs. predictions', fontsize = 15)\n",
    "plt.ylabel('True values for t+1 (global active power)', size=12)\n",
    "plt.xlabel('Predicted values for t+1 (global active power)', size=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Take the difference between the predictions and the true values of the t+1 step of the 7 day multi-step GBM system\n",
    "# Note: The following statistics are based on the model above (60/40 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_gbm = gbm_inv_yhat_save-gbm_inv_y_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean != median -> slightly right-skewed distribution of residuals\n",
    "diff_gbm.mean(), diff_gbm.median()\n",
    "# For comparision:\n",
    "# The experiment in this section (60/40 split) results in: (-84.15365986985809, -82.67020167824012)\n",
    "# The regular model in the notebook (50/50 split) results in: (-151.80721716904435, -128.53251884434917)\n",
    "# The mean residual is twice as high!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals - the shape looks quite good although the upper tail is irregular \n",
    "# The residuals are distributed quite symmetric but the variance of the distribution is quite big, especially see the long tails!\n",
    "# This makes the model costly for us.\n",
    "diff_gbm.plot(kind='kde', color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the quantiles\n",
    "diff_gbm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>9. ASSESSMENT (~200 words)</b> \n",
    "\n",
    "<p> Put your narrative or explanatory text in this cell (or additional cells as necessary) <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>SECTION COMPREHENSION</b>\n",
    "<br>\n",
    "<br>\n",
    "All models are based on the same train-test split. Some models (ARIMA and one LSTM) are doing one-step forecasting, other models (supervised base nd ensembles, 2 LSTMs) are performing multi-step forecast. The choice of the persistence model could have been different as well (e.g. use t-1 instead of t-7 for prediciton of t). The most severe issue we see is the lack of data: We work on a 728 sample train set which is not much to train an algorithm, especially not the LSTMs. The experiment above shows that a 60/40 (instead of 50/50) split decreases RMSE for GMB by 20 already. Second, the data structure changes in the last year and models might be not able to generalise sufficiently. Third, some models are built on more lags and more features than others. Models after the supervised section are comparable. The plot above shows that the predictions vs. true values for GMB do not form a 45 degree line. The result shows that there is lots of potential to improve the predicitve ability of our system. \n",
    "<br>\n",
    "<br>\n",
    "Word count: 176\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "<h1 align=\"center\"> 6. Finalize Model and Summary </h1> <br>\n",
    "<a id=\"final\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network model:\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "    \n",
    "#it can be accest throught the function:\n",
    "#network_model(data, train_test_split, column of the chose of estimation)\n",
    "#it was run in the 7th section of thisnotbook, all results avaliable there\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# GRID SEARCH VROSS VALIDATION OF GRADIENT BOOSTING\n",
    "\n",
    "# !!!\n",
    "# NOTE: DO NOT RUN. We used GridSreachCV to find optimal parameters. It runs for 30 min but the results are not better than the default settings.\n",
    "# So for a final model, see the GBM model in the ensemble section of this notebook. RMSE: 522 (7 days multi-step, direct modeling approach)\n",
    "# !!!\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# By using the supervised data frame, the time-variant/dependent information for each point in time is captured in each row, therefore the rows itself\n",
    "# become time-independent. We can therefore use standard cross-validation with a grid search to find the optimal parameters for all 7 models.\n",
    "\n",
    "#  set paramter ranges\n",
    "parameters = {\n",
    "    \"loss\":[\"ls\"],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"max_depth\":[2,3,5],\n",
    "    \"min_samples_split\":[2,4,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[0.7, 0.85, 0.9],\n",
    "    \"n_estimators\":[100, 200, 500]\n",
    "    }\n",
    "\n",
    "#note that the following code runs \n",
    "#optimised_models = list()\n",
    "#yhat = pd.DataFrame()\n",
    "#for k in range(7):\n",
    "#    model = GridSearchCV(GradientBoostingRegressor(), parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "#    model.fit(train_X, train_y.iloc[:,k])\n",
    "#    yhat['gb_'+str(k)] = model.predict(test_X)\n",
    "#    print('gb_'+str(k)+' GridSearchCV successful')\n",
    "#    optimised_models.append(model)\n",
    "    \n",
    "#print('----------------------------')\n",
    "#inv_yhat = np.concatenate((test_X ,yhat), axis=1)\n",
    "#inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "#inv_yhat = pd.DataFrame(inv_yhat).iloc[:,117:]\n",
    "\n",
    "#inv_y = np.concatenate((test_X, test_y), axis=1#)\n",
    "#inv_y = scaler.inverse_transform(inv_y)\n",
    "#inv_y = pd.DataFrame(inv_y).iloc[:,117:]\n",
    "\n",
    "#temp = list()\n",
    "#for k in range(7):\n",
    "#    print('RMSE t+'+str(k+1)+': '+str(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k]))))\n",
    "#    temp.append(np.sqrt(mean_squared_error(inv_y.iloc[:,k], inv_yhat.iloc[:,k])))\n",
    "#rmse = np.sum(temp)/7    \n",
    "#print('----------------------------')\n",
    "#print('Overall Test RMSE: %.3f' % rmse)\n",
    "\n",
    "#inter=[x for x in range(inv_y.shape[0])]\n",
    "#plt.figure(figsize = (10,7))\n",
    "#plt.plot(inter, inv_y.iloc[:inv_y.shape[0],0], marker='.', label=\"actual\")\n",
    "#plt.plot(inter, inv_yhat.iloc[:inv_y.shape[0],0], 'r', label=\"prediction\")\n",
    "#plt.title('Predictions and actual values for t+1 step - all test data')\n",
    "#plt.ylabel('Global_active_power', size=15)\n",
    "#plt.xlabel('Time step', size=15)\n",
    "#plt.legend(fontsize=15)\n",
    "#plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all seven models available here, just print the first\n",
    "#optimised_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Summary: </b> <br>\n",
    "    \n",
    "As our analysis showed following models were most accurate in their classes:<br>\n",
    "- The ARIMA yields an RMSE of <b>671</b>.<br>\n",
    "- The best model overall: ensamble gradient boosted with RMSE of <b>525</b>.<br>\n",
    "- The best supervised model: polynomial Ridge regression wiht RMSE of <b>899</b>.<br>\n",
    "- The best NN model: Model 3 with 7 lags, all features plus weather and weekend with RMSE of <b>538</b>.<br>\n",
    "- ARIMA performance with RMSE of <b>696</b>.<br>\n",
    "- The evualuation shows that more data would have been needed for training of the models\n",
    "- Using more than 7 days as time lags might increase the predictive ability of the system\n",
    "<br>\n",
    "<br>\n",
    "Word count: 90\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Sources: </b> <br>\n",
    "Code for Neural Networks:  <br>\n",
    "https://www.kaggle.com/amirrezaeian/time-series-data-analysis-using-lstm-tutorial <br>\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>WORD COUNT</b>\n",
    "<br>\n",
    "<br>\n",
    "Notebook 1: 634 <br>\n",
    "Notebook 2: 1200<br>\n",
    "<br>\n",
    "Total word count: < 2000 \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
